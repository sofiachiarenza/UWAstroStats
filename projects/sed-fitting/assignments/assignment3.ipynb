{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4f9a492",
   "metadata": {},
   "source": [
    "# Assignment 3 - SED Fitting\n",
    "\n",
    "## Bayesian Statistics\n",
    "\n",
    "This assignment is split into 3 sections, roughly corresponding to the contents of each of the 3 weeks in the Bayesian Statistics module. \n",
    "\n",
    "All assignments are presented as Jupyter notebooks. You will fork the repository to have your own access to all files. You can edit this notebook directly with your answers and push your changes to GitHub. \n",
    "\n",
    "### **The goal of this assignment is to use different MCMC and Bayesian inference techniques to fit SEDs to galaxy magnitudes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6c87cd",
   "metadata": {},
   "source": [
    "# STEP 0 - Prospector Inputs\n",
    "\n",
    "Prospector has some in-built MCMC techniques that you will have used in Assignment 1 (Emcee or Dynesty). For this assignment you will not be using these in-built tools, instead you will use external libraries to code your own MCMC results and perform model comparison on them. We will however still use prospector for the model so lets prepare that here\n",
    "\n",
    "### The model we are using is a very simple parametric model with 6 free parameters\n",
    "\n",
    "* ### $z$ redshift\n",
    "* ### $M_{\\rm star}$ stellar mass\n",
    "* ### $\\log(z_{\\rm sol})$ metallicity?\n",
    "* ### dust V-band optical depth\n",
    "* ### $t_{\\rm age}$ The age of the host galaxy\n",
    "* ### $\\tau$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ac4c92",
   "metadata": {},
   "source": [
    "1. Activate the enviroment/kernel you used with prospector installed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b11fcda",
   "metadata": {},
   "source": [
    "2. Prepare the prospector model (if you like you can edit the below model, but you dont have to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da7955b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prospect.models import SedModel, priors\n",
    "from prospect.models.templates import TemplateLibrary\n",
    "from prospect.sources import CSPSpecBasis\n",
    "import time\n",
    "\n",
    "model_params = TemplateLibrary[\"parametric_sfh\"]\n",
    "\n",
    "# Let redshift vary\n",
    "model_params[\"zred\"][\"isfree\"] = True\n",
    "model_params['zred']['init'] = 0.1\n",
    "model_params['zred']['prior'] = priors.TopHat(mini=0,maxi=1)\n",
    "\n",
    "# Build the model\n",
    "prospector_model = SedModel(model_params)\n",
    "\n",
    "sps = CSPSpecBasis(zcontinuous=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e549138",
   "metadata": {},
   "source": [
    "3. Load the data vector for a given galaxy (again you can change the gaalxy if you wish, maybe match one of your galaxies from assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8faa4deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sedpy \n",
    "import prospect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "\n",
    "gal_id = 33\n",
    "\n",
    "with fits.open('../data/sw_input.fits') as f:\n",
    "    df = Table(f[1].data).to_pandas()\n",
    "    f.close()\n",
    "\n",
    "def build_obs(gal_id):\n",
    "    \"\"\"Given an object, load in fluxes, convert them to nanomaggies, and create a dict used in Prospector.\"\"\"\n",
    "\n",
    "    inp = {}\n",
    "    \n",
    "    # Get dataframe row for the object\n",
    "    row = df.iloc[gal_id]\n",
    "    inp['redshift'] = row.redshift\n",
    "\n",
    "    # Load the filter response curves from sedpy\n",
    "    bands = [f'sdss_{filt}0' for filt in 'ugriz'] + [f'wise_w{n}' for n in range(1,5)]\n",
    "    filters = sedpy.observate.load_filters(bands)\n",
    "    inp['filters'] = filters\n",
    "    \n",
    "    # Fluxes and uncertainties - already in units of maggies\n",
    "    cols = [f'flux_{filt}' for filt in 'ugriz'] + [f'flux_w{n}' for n in range(1,5)]\n",
    "    fluxes = row[cols].values.astype(float) / 3631\n",
    "\n",
    "    # Errors\n",
    "    cols_err = [f'{col}_e' for col in cols]\n",
    "    errs = row[cols_err].values.astype(float) / 3631\n",
    "\n",
    "    # Anything with a value of 9.999 is null, so may need to mask those fluxes by editing phot_mask\n",
    "    inp['maggies'] = fluxes\n",
    "    inp['maggies_unc'] = errs\n",
    "    inp['phot_mask'] = [True for val in fluxes] # Nothing masked here right now\n",
    "\n",
    "    # This is an array of effective wavelengths for each of the filters.  \n",
    "    # It is not necessary, but it can be useful for plotting so we store it here as a convenience\n",
    "    inp[\"phot_wave\"] = np.array([f.wave_effective for f in inp[\"filters\"]])\n",
    "    inp[\"wavelength\"] = None\n",
    "    \n",
    "    # Populate other fields with default\n",
    "    inp = prospect.utils.obsutils.fix_obs(inp)\n",
    "    return inp\n",
    "\n",
    "obs = build_obs(gal_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c5ccdd",
   "metadata": {},
   "source": [
    "4. Prepare a function that takes the 6 parameters as input, and outputs the predicted fluxes in maggies (once this is set up, you shouldn't have to use prospector directly again for this assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88cc5abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters should enter the function in this order:\n",
      "['zred' 'mass' 'logzsol' 'dust2' 'tage' 'tau']\n"
     ]
    }
   ],
   "source": [
    "#a random sample from the prospectors default priors (just to make sure the model runs)\n",
    "random_input_values = np.array([model_params[k]['prior'].sample()[0] for k in model_params.keys() if model_params[k]['isfree']==True])\n",
    "param_names = np.array([model_params[k]['name'] for k in model_params.keys() if model_params[k]['isfree']==True])\n",
    "print('Parameters should enter the function in this order:')\n",
    "print(param_names)\n",
    "\n",
    "### THIS IS THE FUNCTION YOU CAN USE FOR ALL \n",
    "### YOUR MODEL PREDICTIONS FROM THIS POINT\n",
    "def model(theta):\n",
    "    return prospector_model.predict(theta, obs=obs, sps=sps)[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000afb7f",
   "metadata": {},
   "source": [
    "5. Prospector does some kind of caching under the hood such that the calls to the model that require uncached inputs take much longer than the cached ones\n",
    "\n",
    "We can get around this by initially running the model at enough random parameter inputs to cover all of the possible cached file we will need (there is very likely a better way to do this)\n",
    "\n",
    "Try to avoid calling the model with inputs outside of the range defined below\n",
    "\n",
    "THIS LINE WILL TAKE A COUPLE MINUTES TO RUN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9c7bb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 25.899236917495728s\n",
      "1 26.49707317352295s\n",
      "2 27.990087747573853s\n",
      "3 12.903696775436401s\n",
      "4 13.06036376953125s\n",
      "5 13.435635089874268s\n",
      "6 0.006163835525512695s\n",
      "7 14.149084091186523s\n",
      "8 0.005480051040649414s\n",
      "9 0.00547480583190918s\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "np.random.seed(1)\n",
    "\n",
    "nsamples = 10\n",
    "\n",
    "#prior boundaries\n",
    "zred_min = 0.0\n",
    "zred_max = 1.0\n",
    "logmass_min = 8.0\n",
    "logmass_max = 12.0\n",
    "logzsol_min = -2.0\n",
    "logzsol_max = 0.19\n",
    "dust2_min = 0.0\n",
    "dust2_max = 2.0\n",
    "tage_min = 0.001\n",
    "tage_max = 13.8\n",
    "logtau_min = np.log10(0.1)\n",
    "logtau_max = np.log10(30)\n",
    "theta_min = np.array([zred_min, logmass_min, logzsol_min, dust2_min, tage_min, logtau_min])\n",
    "theta_max = np.array([zred_max, logmass_max, logzsol_max, dust2_max, tage_max, logtau_max])\n",
    "\n",
    "#generate some random input parameter combos\n",
    "lhc_sampling = scipy.stats.qmc.LatinHypercube(6)\n",
    "input_params = theta_min + lhc_sampling.random(nsamples) * (theta_max-theta_min)\n",
    "#un-log the mass and tau \n",
    "input_params[:,1] = 10.**input_params[:,1]\n",
    "input_params[:,5] = 10.**input_params[:,5]\n",
    "\n",
    "model_evals = np.zeros( (nsamples, obs['ndof']) )\n",
    "for i in range(nsamples):\n",
    "    start = time.time()\n",
    "    model_evals[i] = model(input_params[i])\n",
    "    finish = time.time()\n",
    "    print(i, f'{finish-start}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29cfd0a",
   "metadata": {},
   "source": [
    "# SECTION 1 - MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba3bbd9",
   "metadata": {},
   "source": [
    "1. Pick (and install) your 2 favourite MCMC sampling method/implementation you learned about in the lectures (At least 1 of them should be a \"nested\" sampling method, as we will use the features of nested sampling later)\n",
    "\n",
    "Some examples are shown below\n",
    "\n",
    "#### Metropolis-Hastings and Gibbs sampling \n",
    "* The most famous sampling methods \n",
    "* Many people code their own versions\n",
    "* There are many examples and packages online to do this (some examples we haven't tested [here](https://github.com/WenjieZ/easyMH) [here](https://pymcmcstat.readthedocs.io/en/latest/#pymcmcstat) [here](https://numeryst.com/gibbs-sampling-an-introduction-with-python-implementation/#Code_Example))\n",
    "\n",
    "#### Emsemble\n",
    "* More sophisticated samplers \n",
    "* Affine-invariant [EMCEE](https://emcee.readthedocs.io/en/stable/)\n",
    "* KDE [Kombine](https://github.com/bfarr/kombine)\n",
    "\n",
    "#### Nested sampling \n",
    "* [Multinest](https://github.com/rjw57/MultiNest)\n",
    "* [Polychord](https://github.com/PolyChord/PolyChordLite)\n",
    "* [Dynesty](https://dynesty.readthedocs.io/en/latest/index.html) (Has some really great documentation)\n",
    "\n",
    "#### Other \n",
    "* [Nautilus](https://nautilus-sampler.readthedocs.io/en/stable/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d735709",
   "metadata": {},
   "outputs": [],
   "source": [
    "### check they import here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431be806",
   "metadata": {},
   "source": [
    "2. Fit your model to your data using your 2 chosen sampling techniques\n",
    "\n",
    "* Choose flat top-hat priors for all parameters (you can look at your results from Assignment 1 to get some reasonable ranges) \n",
    "* Plot the resulting parameter constraints on top of each other. e.g. in a corner plot\n",
    "* Do they agree with each other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a37fee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Space to work (Sampler 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e45404",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Space to work (Sampler 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4de26f3",
   "metadata": {},
   "source": [
    "3. Did either of your sampling methods have a burn-in? if so make a plot showing the burn-in and justify how much burn-in to remove. If not, explain why there is no burn-in in your methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce2802b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Space to work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c435a6",
   "metadata": {},
   "source": [
    "# SECTION 2 - Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8fd2d0",
   "metadata": {},
   "source": [
    "1. Use the nested sampling technique you chose in Section 1 to compute the Baysian Evidence of your model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4296b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Space to work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1a48d6",
   "metadata": {},
   "source": [
    "2. Change the model in some-way and re-run your nested sampling chain (e.g. add/remove a new parameter, or dramatically change the prior on a parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c572ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Space to work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ebb326",
   "metadata": {},
   "source": [
    "3. Use a Bayesian model comparison technique to decide which model your data prefer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dfe146ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Space to work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237b7702",
   "metadata": {},
   "source": [
    "# SECTION 3 - Comparing results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420060d8",
   "metadata": {},
   "source": [
    "1. How do the conclusions from your \"Bayesian\" model comparison compare to just looking at the change in the best-fit (reduced) chi-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0824488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Space to work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dd6b4d",
   "metadata": {},
   "source": [
    "2. How do your experiences of inferring galaxy properties from MCMC compare to your inference using Machine Learning (Assignment 2 - Section 3)\n",
    "\n",
    "* Which one was more accurate?\n",
    "* What are their limitations?\n",
    "* What unique infomation did the different approaches provide?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "55bfe8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Space to work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
